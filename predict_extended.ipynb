{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1596966349100",
   "display_name": "Python 3.7.6 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import sqrt, log2\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, log_loss, ndcg_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "import joblib\n",
    "import json\n",
    "from fancyimpute import KNN\n",
    "from IPython.display import display_html\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def display_side_by_side(*args):\n",
    "    html_str = ''\n",
    "    for df in args:\n",
    "        html_str += df.to_html()\n",
    "    display_html(html_str.replace('table', 'table style=\"display:inline\"'), raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train_users_2.csv')\n",
    "df_test = pd.read_csv('test_users.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "           id date_account_created  timestamp_first_active date_first_booking  \\\n0  gxn3p5htnn           2010-06-28          20090319043255                NaN   \n1  820tgsjxq7           2011-05-25          20090523174809                NaN   \n2  4ft3gnwmtx           2010-09-28          20090609231247         2010-08-02   \n3  bjjt8pjhuk           2011-12-05          20091031060129         2012-09-08   \n4  87mebub9p4           2010-09-14          20091208061105         2010-02-18   \n\n      gender   age signup_method  signup_flow language affiliate_channel  \\\n0  -unknown-   NaN      facebook            0       en            direct   \n1       MALE  38.0      facebook            0       en               seo   \n2     FEMALE  56.0         basic            3       en            direct   \n3     FEMALE  42.0      facebook            0       en            direct   \n4  -unknown-  41.0         basic            0       en            direct   \n\n  affiliate_provider first_affiliate_tracked signup_app first_device_type  \\\n0             direct               untracked        Web       Mac Desktop   \n1             google               untracked        Web       Mac Desktop   \n2             direct               untracked        Web   Windows Desktop   \n3             direct               untracked        Web       Mac Desktop   \n4             direct               untracked        Web       Mac Desktop   \n\n  first_browser country_destination  \n0        Chrome                 NDF  \n1        Chrome                 NDF  \n2            IE                  US  \n3       Firefox               other  \n4        Chrome                  US  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>date_account_created</th>\n      <th>timestamp_first_active</th>\n      <th>date_first_booking</th>\n      <th>gender</th>\n      <th>age</th>\n      <th>signup_method</th>\n      <th>signup_flow</th>\n      <th>language</th>\n      <th>affiliate_channel</th>\n      <th>affiliate_provider</th>\n      <th>first_affiliate_tracked</th>\n      <th>signup_app</th>\n      <th>first_device_type</th>\n      <th>first_browser</th>\n      <th>country_destination</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>gxn3p5htnn</td>\n      <td>2010-06-28</td>\n      <td>20090319043255</td>\n      <td>NaN</td>\n      <td>-unknown-</td>\n      <td>NaN</td>\n      <td>facebook</td>\n      <td>0</td>\n      <td>en</td>\n      <td>direct</td>\n      <td>direct</td>\n      <td>untracked</td>\n      <td>Web</td>\n      <td>Mac Desktop</td>\n      <td>Chrome</td>\n      <td>NDF</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>820tgsjxq7</td>\n      <td>2011-05-25</td>\n      <td>20090523174809</td>\n      <td>NaN</td>\n      <td>MALE</td>\n      <td>38.0</td>\n      <td>facebook</td>\n      <td>0</td>\n      <td>en</td>\n      <td>seo</td>\n      <td>google</td>\n      <td>untracked</td>\n      <td>Web</td>\n      <td>Mac Desktop</td>\n      <td>Chrome</td>\n      <td>NDF</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4ft3gnwmtx</td>\n      <td>2010-09-28</td>\n      <td>20090609231247</td>\n      <td>2010-08-02</td>\n      <td>FEMALE</td>\n      <td>56.0</td>\n      <td>basic</td>\n      <td>3</td>\n      <td>en</td>\n      <td>direct</td>\n      <td>direct</td>\n      <td>untracked</td>\n      <td>Web</td>\n      <td>Windows Desktop</td>\n      <td>IE</td>\n      <td>US</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>bjjt8pjhuk</td>\n      <td>2011-12-05</td>\n      <td>20091031060129</td>\n      <td>2012-09-08</td>\n      <td>FEMALE</td>\n      <td>42.0</td>\n      <td>facebook</td>\n      <td>0</td>\n      <td>en</td>\n      <td>direct</td>\n      <td>direct</td>\n      <td>untracked</td>\n      <td>Web</td>\n      <td>Mac Desktop</td>\n      <td>Firefox</td>\n      <td>other</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>87mebub9p4</td>\n      <td>2010-09-14</td>\n      <td>20091208061105</td>\n      <td>2010-02-18</td>\n      <td>-unknown-</td>\n      <td>41.0</td>\n      <td>basic</td>\n      <td>0</td>\n      <td>en</td>\n      <td>direct</td>\n      <td>direct</td>\n      <td>untracked</td>\n      <td>Web</td>\n      <td>Mac Desktop</td>\n      <td>Chrome</td>\n      <td>US</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "           id date_account_created  timestamp_first_active  \\\n0  5uwns89zht           2014-07-01          20140701000006   \n1  jtl0dijy2j           2014-07-01          20140701000051   \n2  xx0ulgorjt           2014-07-01          20140701000148   \n3  6c6puo6ix0           2014-07-01          20140701000215   \n4  czqhjk3yfe           2014-07-01          20140701000305   \n\n   date_first_booking     gender   age signup_method  signup_flow language  \\\n0                 NaN     FEMALE  35.0      facebook            0       en   \n1                 NaN  -unknown-   NaN         basic            0       en   \n2                 NaN  -unknown-   NaN         basic            0       en   \n3                 NaN  -unknown-   NaN         basic            0       en   \n4                 NaN  -unknown-   NaN         basic            0       en   \n\n  affiliate_channel affiliate_provider first_affiliate_tracked signup_app  \\\n0            direct             direct               untracked      Moweb   \n1            direct             direct               untracked      Moweb   \n2            direct             direct                  linked        Web   \n3            direct             direct                  linked        Web   \n4            direct             direct               untracked        Web   \n\n  first_device_type  first_browser  \n0            iPhone  Mobile Safari  \n1            iPhone  Mobile Safari  \n2   Windows Desktop         Chrome  \n3   Windows Desktop             IE  \n4       Mac Desktop         Safari  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>date_account_created</th>\n      <th>timestamp_first_active</th>\n      <th>date_first_booking</th>\n      <th>gender</th>\n      <th>age</th>\n      <th>signup_method</th>\n      <th>signup_flow</th>\n      <th>language</th>\n      <th>affiliate_channel</th>\n      <th>affiliate_provider</th>\n      <th>first_affiliate_tracked</th>\n      <th>signup_app</th>\n      <th>first_device_type</th>\n      <th>first_browser</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5uwns89zht</td>\n      <td>2014-07-01</td>\n      <td>20140701000006</td>\n      <td>NaN</td>\n      <td>FEMALE</td>\n      <td>35.0</td>\n      <td>facebook</td>\n      <td>0</td>\n      <td>en</td>\n      <td>direct</td>\n      <td>direct</td>\n      <td>untracked</td>\n      <td>Moweb</td>\n      <td>iPhone</td>\n      <td>Mobile Safari</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>jtl0dijy2j</td>\n      <td>2014-07-01</td>\n      <td>20140701000051</td>\n      <td>NaN</td>\n      <td>-unknown-</td>\n      <td>NaN</td>\n      <td>basic</td>\n      <td>0</td>\n      <td>en</td>\n      <td>direct</td>\n      <td>direct</td>\n      <td>untracked</td>\n      <td>Moweb</td>\n      <td>iPhone</td>\n      <td>Mobile Safari</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>xx0ulgorjt</td>\n      <td>2014-07-01</td>\n      <td>20140701000148</td>\n      <td>NaN</td>\n      <td>-unknown-</td>\n      <td>NaN</td>\n      <td>basic</td>\n      <td>0</td>\n      <td>en</td>\n      <td>direct</td>\n      <td>direct</td>\n      <td>linked</td>\n      <td>Web</td>\n      <td>Windows Desktop</td>\n      <td>Chrome</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6c6puo6ix0</td>\n      <td>2014-07-01</td>\n      <td>20140701000215</td>\n      <td>NaN</td>\n      <td>-unknown-</td>\n      <td>NaN</td>\n      <td>basic</td>\n      <td>0</td>\n      <td>en</td>\n      <td>direct</td>\n      <td>direct</td>\n      <td>linked</td>\n      <td>Web</td>\n      <td>Windows Desktop</td>\n      <td>IE</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>czqhjk3yfe</td>\n      <td>2014-07-01</td>\n      <td>20140701000305</td>\n      <td>NaN</td>\n      <td>-unknown-</td>\n      <td>NaN</td>\n      <td>basic</td>\n      <td>0</td>\n      <td>en</td>\n      <td>direct</td>\n      <td>direct</td>\n      <td>untracked</td>\n      <td>Web</td>\n      <td>Mac Desktop</td>\n      <td>Safari</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Target Classes: ['AU' 'CA' 'DE' 'ES' 'FR' 'GB' 'IT' 'NDF' 'NL' 'PT' 'US' 'other']\nTrain Set: (213451, 16)\nTest Set: (62096, 15)\n"
    }
   ],
   "source": [
    "print('Target Classes: ' + str(np.unique(df_train['country_destination'].values)))\n",
    "print('Train Set: ' + str(df_train.shape))\n",
    "print('Test Set: ' + str(df_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "True True\n"
    }
   ],
   "source": [
    "# Check if id coloumn is unique\n",
    "print(df_train['id'].is_unique, df_test['id'].is_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train Set\n----------------------\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 213451 entries, 0 to 213450\nData columns (total 16 columns):\n #   Column                   Non-Null Count   Dtype  \n---  ------                   --------------   -----  \n 0   id                       213451 non-null  object \n 1   date_account_created     213451 non-null  object \n 2   timestamp_first_active   213451 non-null  int64  \n 3   date_first_booking       88908 non-null   object \n 4   gender                   213451 non-null  object \n 5   age                      125461 non-null  float64\n 6   signup_method            213451 non-null  object \n 7   signup_flow              213451 non-null  int64  \n 8   language                 213451 non-null  object \n 9   affiliate_channel        213451 non-null  object \n 10  affiliate_provider       213451 non-null  object \n 11  first_affiliate_tracked  207386 non-null  object \n 12  signup_app               213451 non-null  object \n 13  first_device_type        213451 non-null  object \n 14  first_browser            213451 non-null  object \n 15  country_destination      213451 non-null  object \ndtypes: float64(1), int64(2), object(13)\nmemory usage: 26.1+ MB\nNone\n\n\nTrain Set Null Values:\n----------------------\ndate_first_booking: 124543\nage: 87990\nfirst_affiliate_tracked: 6065\n\n---------------------------------------------------------------------\n\nTest Set\n----------------------\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 62096 entries, 0 to 62095\nData columns (total 15 columns):\n #   Column                   Non-Null Count  Dtype  \n---  ------                   --------------  -----  \n 0   id                       62096 non-null  object \n 1   date_account_created     62096 non-null  object \n 2   timestamp_first_active   62096 non-null  int64  \n 3   date_first_booking       0 non-null      float64\n 4   gender                   62096 non-null  object \n 5   age                      33220 non-null  float64\n 6   signup_method            62096 non-null  object \n 7   signup_flow              62096 non-null  int64  \n 8   language                 62096 non-null  object \n 9   affiliate_channel        62096 non-null  object \n 10  affiliate_provider       62096 non-null  object \n 11  first_affiliate_tracked  62076 non-null  object \n 12  signup_app               62096 non-null  object \n 13  first_device_type        62096 non-null  object \n 14  first_browser            62096 non-null  object \ndtypes: float64(2), int64(2), object(11)\nmemory usage: 7.1+ MB\nNone\n\n\nTest Null Values:\n----------------------\ndate_first_booking: 62096\nage: 28876\nfirst_affiliate_tracked: 20\n"
    }
   ],
   "source": [
    "print('Train Set\\n----------------------')\n",
    "print(df_train.info())\n",
    "print()\n",
    "print('\\nTrain Set Null Values:\\n----------------------')\n",
    "for i in df_train.columns:\n",
    "    sum = df_train[i].isnull().sum()\n",
    "    if sum != 0:\n",
    "        print(i + ': {}'.format(sum))\n",
    "\n",
    "print('\\n---------------------------------------------------------------------\\n')\n",
    "\n",
    "print('Test Set\\n----------------------')\n",
    "print(df_test.info())\n",
    "print()\n",
    "print('\\nTest Null Values:\\n----------------------')\n",
    "for i in df_test.columns:\n",
    "    sum = df_test[i].isnull().sum()\n",
    "    if sum != 0:\n",
    "        print(i + ': {}'.format(sum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": "<table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Train Age</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>125461.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>49.668335</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>155.666612</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>28.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>34.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>43.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>2014.000000</td>\n    </tr>\n  </tbody>\n</table style=\"display:inline\"><table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Test Age</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>33220.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>37.616677</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>74.440647</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>26.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>31.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>40.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>2002.000000</td>\n    </tr>\n  </tbody>\n</table style=\"display:inline\">"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": "<table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Train Gender</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>-unknown-</th>\n      <td>95688</td>\n    </tr>\n    <tr>\n      <th>FEMALE</th>\n      <td>63041</td>\n    </tr>\n    <tr>\n      <th>MALE</th>\n      <td>54440</td>\n    </tr>\n    <tr>\n      <th>OTHER</th>\n      <td>282</td>\n    </tr>\n  </tbody>\n</table style=\"display:inline\"><table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Test Gender</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>-unknown-</th>\n      <td>33792</td>\n    </tr>\n    <tr>\n      <th>FEMALE</th>\n      <td>14483</td>\n    </tr>\n    <tr>\n      <th>MALE</th>\n      <td>13769</td>\n    </tr>\n    <tr>\n      <th>OTHER</th>\n      <td>52</td>\n    </tr>\n  </tbody>\n</table style=\"display:inline\">"
     },
     "metadata": {}
    }
   ],
   "source": [
    "df1 = pd.DataFrame(data=df_train['age'].describe())\n",
    "df2 = pd.DataFrame(data=df_test['age'].describe())\n",
    "df1.rename(columns={'age': 'Train Age'}, inplace=True)\n",
    "df2.rename(columns={'age': 'Test Age'}, inplace=True)\n",
    "display_side_by_side(df1, df2)\n",
    "df1 = pd.DataFrame(data=df_train['gender'].value_counts())\n",
    "df2 = pd.DataFrame(data=df_test['gender'].value_counts())\n",
    "df1.rename(columns={'gender': 'Train Gender'}, inplace=True)\n",
    "df2.rename(columns={'gender': 'Test Gender'}, inplace=True)\n",
    "display_side_by_side(df1, df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -unknown- frequency in gender coloumn is nearly as half as much of the total number of samples.\n",
    "# Removing or replacing this value with mean/media or imputing using knn will definitely generate noise. Therefore, it's best to leave it as is.\n",
    "# Handling missing values for test sets is usually problematic especially for features that are both imprtant and have large numbers of missing values.\n",
    "# I will concatenate train and test sets to fill missing values using knn and then seperate them back.\n",
    "# This approach will ensure reasonable accuracy.\n",
    "\n",
    "# No need for id coloumn\n",
    "df_train.drop(['id'], axis=1, inplace=True)\n",
    "df_test.drop(['id'], axis=1, inplace=True)\n",
    "\n",
    "# date_first_booking is completely empty in the test set, therefore we will remove this coloumn.\n",
    "df_train.drop(['date_first_booking'], axis=1, inplace=True)\n",
    "df_test.drop(['date_first_booking'], axis=1, inplace=True)\n",
    "\n",
    "# There is a minimum age 1 and maximum 2014. Obviously there are outliers in the age coloumn. Taking Airbnb's terms of service into account (users must be 18 years or older), we will assume an age range between 18-117 (the age of the oldest living person as of 02/AUG/2020)\n",
    "df_train['age'] = df_train['age'].apply(lambda x: np.nan if ((x < 18) or (x > 117)) else x)\n",
    "df_test['age'] = df_test['age'].apply(lambda x: np.nan if ((x < 18) or (x > 117)) else x)\n",
    "\n",
    "#df_train['age_bucket'] = pd.cut(df_train['age'], [18, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 120], right=False)\n",
    "#df_test['age_bucket'] = pd.cut(df_test['age'], [18, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 120], right=False)\n",
    "\n",
    "#df_train['gender'].replace('-unknown-', np.nan, inplace = True)\n",
    "#df_test['gender'].replace('-unknown-', np.nan, inplace = True)\n",
    "\n",
    "# Extracting different time features from 'date_account_created' and 'timestamp_first_active'\n",
    "seasons = {1: 'winter', 2:'winter', 12:'winter', 3:'spring', 4:'spring', 5:'spring', 6:'summer', 7:'summer', 8:'summer', 9:'autumn', 10:'autumn', 11:'autumn'}\n",
    "\n",
    "# Train Set\n",
    "df_train['date_account_created'] = pd.to_datetime(df_train['date_account_created'])\n",
    "df_train['year_ac'] = pd.DatetimeIndex(df_train['date_account_created']).year\n",
    "df_train['month_ac'] = pd.DatetimeIndex(df_train['date_account_created']).month\n",
    "df_train['day_ac'] = pd.DatetimeIndex(df_train['date_account_created']).day\n",
    "df_train['weekday_ac'] = pd.DatetimeIndex(df_train['date_account_created']).weekday\n",
    "df_train['season_ac'] = df_train['month_ac'].apply(lambda x: seasons[x])\n",
    "\n",
    "df_train['time_first_active'] = pd.to_datetime((df_train['timestamp_first_active']), format='%Y%m%d%H%M%S')\n",
    "df_train['year_fa'] = pd.DatetimeIndex(df_train['time_first_active']).year\n",
    "df_train['month_fa'] = pd.DatetimeIndex(df_train['time_first_active']).month\n",
    "df_train['day_fa'] = pd.DatetimeIndex(df_train['time_first_active']).day\n",
    "df_train['weekday_fa'] = pd.DatetimeIndex(df_train['time_first_active']).weekday\n",
    "df_train['season_fa'] = df_train['month_fa'].apply(lambda x: seasons[x])\n",
    "\n",
    "df_train.drop(['date_account_created'], axis=1, inplace=True)\n",
    "df_train.drop(['timestamp_first_active'], axis=1, inplace=True)\n",
    "df_train.drop(['time_first_active'], axis=1, inplace=True)\n",
    "\n",
    "# Test Set\n",
    "df_test['date_account_created'] = pd.to_datetime(df_test['date_account_created'])\n",
    "df_test['year_ac'] = pd.DatetimeIndex(df_test['date_account_created']).year\n",
    "df_test['month_ac'] = pd.DatetimeIndex(df_test['date_account_created']).month\n",
    "df_test['day_ac'] = pd.DatetimeIndex(df_test['date_account_created']).day\n",
    "df_test['weekday_ac'] = pd.DatetimeIndex(df_test['date_account_created']).weekday\n",
    "df_test['season_ac'] = df_test['month_ac'].apply(lambda x: seasons[x])\n",
    "\n",
    "df_test['time_first_active'] = pd.to_datetime((df_test['timestamp_first_active']), format='%Y%m%d%H%M%S')\n",
    "df_test['year_fa'] = pd.DatetimeIndex(df_test['time_first_active']).year\n",
    "df_test['month_fa'] = pd.DatetimeIndex(df_test['time_first_active']).month\n",
    "df_test['day_fa'] = pd.DatetimeIndex(df_test['time_first_active']).day\n",
    "df_test['weekday_fa'] = pd.DatetimeIndex(df_test['time_first_active']).weekday\n",
    "df_test['season_fa'] = df_test['month_fa'].apply(lambda x: seasons[x])\n",
    "\n",
    "df_test.drop(['date_account_created'], axis=1, inplace=True)\n",
    "df_test.drop(['timestamp_first_active'], axis=1, inplace=True)\n",
    "df_test.drop(['time_first_active'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": "<table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Train Age</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>124522.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>37.443857</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>13.930721</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>18.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>28.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>34.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>43.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>115.000000</td>\n    </tr>\n  </tbody>\n</table style=\"display:inline\"><table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Test Age</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>33141.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>34.818352</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>13.142475</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>18.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>26.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>31.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>40.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>110.000000</td>\n    </tr>\n  </tbody>\n</table style=\"display:inline\">"
     },
     "metadata": {}
    }
   ],
   "source": [
    "df1 = pd.DataFrame(data=df_train['age'].describe())\n",
    "df2 = pd.DataFrame(data=df_test['age'].describe())\n",
    "df1.rename(columns={'age': 'Train Age'}, inplace=True)\n",
    "df2.rename(columns={'age': 'Test Age'}, inplace=True)\n",
    "display_side_by_side(df1, df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": "<table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Train signup_method</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>basic</th>\n      <td>152897</td>\n    </tr>\n    <tr>\n      <th>facebook</th>\n      <td>60008</td>\n    </tr>\n    <tr>\n      <th>google</th>\n      <td>546</td>\n    </tr>\n  </tbody>\n</table style=\"display:inline\"><table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Test signup_method</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>basic</th>\n      <td>45325</td>\n    </tr>\n    <tr>\n      <th>facebook</th>\n      <td>14856</td>\n    </tr>\n    <tr>\n      <th>google</th>\n      <td>1892</td>\n    </tr>\n    <tr>\n      <th>weibo</th>\n      <td>23</td>\n    </tr>\n  </tbody>\n</table style=\"display:inline\">"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": "<table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Train signup_flow</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>164739</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>14659</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>9329</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>8822</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>6881</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>4328</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>2835</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1047</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>301</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>240</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>196</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>36</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table style=\"display:inline\"><table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Test signup_flow</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>41353</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>15175</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>3573</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>1915</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>75</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table style=\"display:inline\">"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": "<table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Train language</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>en</th>\n      <td>206314</td>\n    </tr>\n    <tr>\n      <th>zh</th>\n      <td>1632</td>\n    </tr>\n    <tr>\n      <th>fr</th>\n      <td>1172</td>\n    </tr>\n    <tr>\n      <th>es</th>\n      <td>915</td>\n    </tr>\n    <tr>\n      <th>ko</th>\n      <td>747</td>\n    </tr>\n    <tr>\n      <th>de</th>\n      <td>732</td>\n    </tr>\n    <tr>\n      <th>it</th>\n      <td>514</td>\n    </tr>\n    <tr>\n      <th>ru</th>\n      <td>389</td>\n    </tr>\n    <tr>\n      <th>pt</th>\n      <td>240</td>\n    </tr>\n    <tr>\n      <th>ja</th>\n      <td>225</td>\n    </tr>\n    <tr>\n      <th>sv</th>\n      <td>122</td>\n    </tr>\n    <tr>\n      <th>nl</th>\n      <td>97</td>\n    </tr>\n    <tr>\n      <th>tr</th>\n      <td>64</td>\n    </tr>\n    <tr>\n      <th>da</th>\n      <td>58</td>\n    </tr>\n    <tr>\n      <th>pl</th>\n      <td>54</td>\n    </tr>\n    <tr>\n      <th>cs</th>\n      <td>32</td>\n    </tr>\n    <tr>\n      <th>no</th>\n      <td>30</td>\n    </tr>\n    <tr>\n      <th>el</th>\n      <td>24</td>\n    </tr>\n    <tr>\n      <th>th</th>\n      <td>24</td>\n    </tr>\n    <tr>\n      <th>id</th>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>hu</th>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>fi</th>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>ca</th>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>is</th>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>hr</th>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table style=\"display:inline\"><table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Test language</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>en</th>\n      <td>59224</td>\n    </tr>\n    <tr>\n      <th>zh</th>\n      <td>1002</td>\n    </tr>\n    <tr>\n      <th>ko</th>\n      <td>369</td>\n    </tr>\n    <tr>\n      <th>fr</th>\n      <td>336</td>\n    </tr>\n    <tr>\n      <th>es</th>\n      <td>259</td>\n    </tr>\n    <tr>\n      <th>de</th>\n      <td>245</td>\n    </tr>\n    <tr>\n      <th>ja</th>\n      <td>120</td>\n    </tr>\n    <tr>\n      <th>ru</th>\n      <td>119</td>\n    </tr>\n    <tr>\n      <th>it</th>\n      <td>119</td>\n    </tr>\n    <tr>\n      <th>pt</th>\n      <td>82</td>\n    </tr>\n    <tr>\n      <th>sv</th>\n      <td>54</td>\n    </tr>\n    <tr>\n      <th>nl</th>\n      <td>37</td>\n    </tr>\n    <tr>\n      <th>tr</th>\n      <td>28</td>\n    </tr>\n    <tr>\n      <th>pl</th>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>no</th>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>da</th>\n      <td>17</td>\n    </tr>\n    <tr>\n      <th>cs</th>\n      <td>17</td>\n    </tr>\n    <tr>\n      <th>hu</th>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>el</th>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>fi</th>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>th</th>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>-unknown-</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>id</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>ca</th>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table style=\"display:inline\">"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": "<table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Train affiliate_provider</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>direct</th>\n      <td>137426</td>\n    </tr>\n    <tr>\n      <th>google</th>\n      <td>51693</td>\n    </tr>\n    <tr>\n      <th>other</th>\n      <td>12549</td>\n    </tr>\n    <tr>\n      <th>craigslist</th>\n      <td>3471</td>\n    </tr>\n    <tr>\n      <th>bing</th>\n      <td>2328</td>\n    </tr>\n    <tr>\n      <th>facebook</th>\n      <td>2273</td>\n    </tr>\n    <tr>\n      <th>vast</th>\n      <td>829</td>\n    </tr>\n    <tr>\n      <th>padmapper</th>\n      <td>768</td>\n    </tr>\n    <tr>\n      <th>facebook-open-graph</th>\n      <td>545</td>\n    </tr>\n    <tr>\n      <th>yahoo</th>\n      <td>496</td>\n    </tr>\n    <tr>\n      <th>gsp</th>\n      <td>453</td>\n    </tr>\n    <tr>\n      <th>meetup</th>\n      <td>347</td>\n    </tr>\n    <tr>\n      <th>email-marketing</th>\n      <td>166</td>\n    </tr>\n    <tr>\n      <th>naver</th>\n      <td>52</td>\n    </tr>\n    <tr>\n      <th>baidu</th>\n      <td>29</td>\n    </tr>\n    <tr>\n      <th>yandex</th>\n      <td>17</td>\n    </tr>\n    <tr>\n      <th>wayn</th>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>daum</th>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table style=\"display:inline\"><table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Test affiliate_provider</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>direct</th>\n      <td>43844</td>\n    </tr>\n    <tr>\n      <th>google</th>\n      <td>14263</td>\n    </tr>\n    <tr>\n      <th>facebook</th>\n      <td>1723</td>\n    </tr>\n    <tr>\n      <th>bing</th>\n      <td>1391</td>\n    </tr>\n    <tr>\n      <th>other</th>\n      <td>487</td>\n    </tr>\n    <tr>\n      <th>yahoo</th>\n      <td>157</td>\n    </tr>\n    <tr>\n      <th>email-marketing</th>\n      <td>104</td>\n    </tr>\n    <tr>\n      <th>padmapper</th>\n      <td>68</td>\n    </tr>\n    <tr>\n      <th>facebook-open-graph</th>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>naver</th>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>meetup</th>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>craigslist</th>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>baidu</th>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>gsp</th>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>daum</th>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>vast</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>yandex</th>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table style=\"display:inline\">"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": "<table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Train first_device_type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Mac Desktop</th>\n      <td>89600</td>\n    </tr>\n    <tr>\n      <th>Windows Desktop</th>\n      <td>72716</td>\n    </tr>\n    <tr>\n      <th>iPhone</th>\n      <td>20759</td>\n    </tr>\n    <tr>\n      <th>iPad</th>\n      <td>14339</td>\n    </tr>\n    <tr>\n      <th>Other/Unknown</th>\n      <td>10667</td>\n    </tr>\n    <tr>\n      <th>Android Phone</th>\n      <td>2803</td>\n    </tr>\n    <tr>\n      <th>Android Tablet</th>\n      <td>1292</td>\n    </tr>\n    <tr>\n      <th>Desktop (Other)</th>\n      <td>1199</td>\n    </tr>\n    <tr>\n      <th>SmartPhone (Other)</th>\n      <td>76</td>\n    </tr>\n  </tbody>\n</table style=\"display:inline\"><table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Test first_device_type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>iPhone</th>\n      <td>19055</td>\n    </tr>\n    <tr>\n      <th>Mac Desktop</th>\n      <td>16728</td>\n    </tr>\n    <tr>\n      <th>Windows Desktop</th>\n      <td>14232</td>\n    </tr>\n    <tr>\n      <th>Android Phone</th>\n      <td>6655</td>\n    </tr>\n    <tr>\n      <th>iPad</th>\n      <td>3697</td>\n    </tr>\n    <tr>\n      <th>Android Tablet</th>\n      <td>806</td>\n    </tr>\n    <tr>\n      <th>Other/Unknown</th>\n      <td>500</td>\n    </tr>\n    <tr>\n      <th>Desktop (Other)</th>\n      <td>308</td>\n    </tr>\n    <tr>\n      <th>SmartPhone (Other)</th>\n      <td>115</td>\n    </tr>\n  </tbody>\n</table style=\"display:inline\">"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": "<table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Train first_browser</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Chrome</th>\n      <td>63845</td>\n    </tr>\n    <tr>\n      <th>Safari</th>\n      <td>45169</td>\n    </tr>\n    <tr>\n      <th>Firefox</th>\n      <td>33655</td>\n    </tr>\n    <tr>\n      <th>-unknown-</th>\n      <td>27266</td>\n    </tr>\n    <tr>\n      <th>IE</th>\n      <td>21068</td>\n    </tr>\n    <tr>\n      <th>Mobile Safari</th>\n      <td>19274</td>\n    </tr>\n    <tr>\n      <th>Chrome Mobile</th>\n      <td>1270</td>\n    </tr>\n    <tr>\n      <th>Android Browser</th>\n      <td>851</td>\n    </tr>\n    <tr>\n      <th>AOL Explorer</th>\n      <td>245</td>\n    </tr>\n    <tr>\n      <th>Opera</th>\n      <td>188</td>\n    </tr>\n    <tr>\n      <th>Silk</th>\n      <td>124</td>\n    </tr>\n    <tr>\n      <th>Chromium</th>\n      <td>73</td>\n    </tr>\n    <tr>\n      <th>BlackBerry Browser</th>\n      <td>53</td>\n    </tr>\n    <tr>\n      <th>Maxthon</th>\n      <td>46</td>\n    </tr>\n    <tr>\n      <th>Apple Mail</th>\n      <td>36</td>\n    </tr>\n    <tr>\n      <th>IE Mobile</th>\n      <td>36</td>\n    </tr>\n    <tr>\n      <th>Sogou Explorer</th>\n      <td>33</td>\n    </tr>\n    <tr>\n      <th>Mobile Firefox</th>\n      <td>30</td>\n    </tr>\n    <tr>\n      <th>SiteKiosk</th>\n      <td>24</td>\n    </tr>\n    <tr>\n      <th>RockMelt</th>\n      <td>24</td>\n    </tr>\n    <tr>\n      <th>Iron</th>\n      <td>17</td>\n    </tr>\n    <tr>\n      <th>IceWeasel</th>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>Pale Moon</th>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>Yandex.Browser</th>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>CometBird</th>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>SeaMonkey</th>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>Camino</th>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>TenFourFox</th>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>wOSBrowser</th>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>CoolNovo</th>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>Avant Browser</th>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>Opera Mini</th>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>Mozilla</th>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>OmniWeb</th>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>Crazy Browser</th>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>SlimBrowser</th>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>TheWorld Browser</th>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>Flock</th>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>Comodo Dragon</th>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>Opera Mobile</th>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>Stainless</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>NetNewsWire</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>Googlebot</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>PS Vita browser</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>Palm Pre web browser</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>Epic</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>IceDragon</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>Google Earth</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>Conkeror</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>Arora</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>Kindle Browser</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>Outlook 2007</th>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table style=\"display:inline\"><table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Test first_browser</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>-unknown-</th>\n      <td>17128</td>\n    </tr>\n    <tr>\n      <th>Chrome</th>\n      <td>14826</td>\n    </tr>\n    <tr>\n      <th>Mobile Safari</th>\n      <td>10362</td>\n    </tr>\n    <tr>\n      <th>Safari</th>\n      <td>8133</td>\n    </tr>\n    <tr>\n      <th>Firefox</th>\n      <td>5010</td>\n    </tr>\n    <tr>\n      <th>IE</th>\n      <td>3676</td>\n    </tr>\n    <tr>\n      <th>Chrome Mobile</th>\n      <td>1916</td>\n    </tr>\n    <tr>\n      <th>Android Browser</th>\n      <td>726</td>\n    </tr>\n    <tr>\n      <th>IE Mobile</th>\n      <td>82</td>\n    </tr>\n    <tr>\n      <th>Silk</th>\n      <td>48</td>\n    </tr>\n    <tr>\n      <th>Opera</th>\n      <td>40</td>\n    </tr>\n    <tr>\n      <th>BlackBerry Browser</th>\n      <td>36</td>\n    </tr>\n    <tr>\n      <th>Mobile Firefox</th>\n      <td>34</td>\n    </tr>\n    <tr>\n      <th>Maxthon</th>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>Chromium</th>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>Sogou Explorer</th>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>Apple Mail</th>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>AOL Explorer</th>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>Iron</th>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>Opera Mini</th>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>Yandex.Browser</th>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>SiteKiosk</th>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>Opera Mobile</th>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>IceWeasel</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>wOSBrowser</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>CometBird</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>IBrowse</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>Pale Moon</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>SeaMonkey</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>UC Browser</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>Nintendo Browser</th>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table style=\"display:inline\">"
     },
     "metadata": {}
    }
   ],
   "source": [
    "df1 = pd.DataFrame(data=df_train['signup_method'].value_counts())\n",
    "df2 = pd.DataFrame(data=df_test['signup_method'].value_counts())\n",
    "df1.rename(columns={'signup_method': 'Train signup_method'}, inplace=True)\n",
    "df2.rename(columns={'signup_method': 'Test signup_method'}, inplace=True)\n",
    "display_side_by_side(df1, df2)\n",
    "\n",
    "df1 = pd.DataFrame(data=df_train['signup_flow'].value_counts())\n",
    "df2 = pd.DataFrame(data=df_test['signup_flow'].value_counts())\n",
    "df1.rename(columns={'signup_flow': 'Train signup_flow'}, inplace=True)\n",
    "df2.rename(columns={'signup_flow': 'Test signup_flow'}, inplace=True)\n",
    "display_side_by_side(df1, df2)\n",
    "\n",
    "df1 = pd.DataFrame(data=df_train['language'].value_counts())\n",
    "df2 = pd.DataFrame(data=df_test['language'].value_counts())\n",
    "df1.rename(columns={'language': 'Train language'}, inplace=True)\n",
    "df2.rename(columns={'language': 'Test language'}, inplace=True)\n",
    "display_side_by_side(df1, df2)\n",
    "\n",
    "df1 = pd.DataFrame(data=df_train['affiliate_provider'].value_counts())\n",
    "df2 = pd.DataFrame(data=df_test['affiliate_provider'].value_counts())\n",
    "df1.rename(columns={'affiliate_provider': 'Train affiliate_provider'}, inplace=True)\n",
    "df2.rename(columns={'affiliate_provider': 'Test affiliate_provider'}, inplace=True)\n",
    "display_side_by_side(df1, df2)\n",
    "\n",
    "df1 = pd.DataFrame(data=df_train['first_device_type'].value_counts())\n",
    "df2 = pd.DataFrame(data=df_test['first_device_type'].value_counts())\n",
    "df1.rename(columns={'first_device_type': 'Train first_device_type'}, inplace=True)\n",
    "df2.rename(columns={'first_device_type': 'Test first_device_type'}, inplace=True)\n",
    "display_side_by_side(df1, df2)\n",
    "\n",
    "df1 = pd.DataFrame(data=df_train['first_browser'].value_counts())\n",
    "df2 = pd.DataFrame(data=df_test['first_browser'].value_counts())\n",
    "df1.rename(columns={'first_browser': 'Train first_browser'}, inplace=True)\n",
    "df2.rename(columns={'first_browser': 'Test first_browser'}, inplace=True)\n",
    "display_side_by_side(df1, df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = pd.concat([df_train,df_test], keys=[0,1])\n",
    "\n",
    "# Frequency dictionaries\n",
    "frq_suf = df_temp['signup_flow'].value_counts().to_dict()\n",
    "frq_lang = df_temp['language'].value_counts().to_dict()\n",
    "frq_ap = df_temp['affiliate_provider'].value_counts().to_dict()\n",
    "frq_fdt = df_temp['first_device_type'].value_counts().to_dict()\n",
    "frq_brws = df_temp['first_browser'].value_counts().to_dict()\n",
    "\n",
    "threshold = 37 #group values below this threshold\n",
    "\n",
    "df_temp['signup_flow'] = df_train['signup_flow'].apply(lambda x: 'other' if frq_suf[x] < threshold else x)\n",
    "df_temp['language'] = df_train['language'].apply(lambda x: 'other' if frq_lang[x] < threshold else x)\n",
    "df_temp['affiliate_provider'] = df_train['affiliate_provider'].apply(lambda x: 'other' if frq_ap[x] < threshold else x)\n",
    "df_temp['first_device_type'].replace(['Mac Desktop', 'Windows Desktop', 'Desktop (Other)'], 'Desktop', inplace = True)\n",
    "df_temp['first_device_type'].replace(['iPhone', 'Android Phone', 'SmartPhone (Other)'], 'Smartphone', inplace = True)\n",
    "df_temp['first_device_type'].replace(['iPad', 'Android Tablet'], 'Tablet', inplace = True)\n",
    "df_temp['first_browser'] = df_train['first_browser'].apply(lambda x: 'other' if frq_brws[x] < threshold else x)\n",
    "\n",
    "# Previously I extracted seasons from month_ac and month_fa to use for prediction and data visualisation.\n",
    "# I realise now that this may create problems when predicting due to the fact that month and season features are highly correlated.\n",
    "# Will be kept above for visualisation purposes (later).\n",
    "df_temp.drop(['season_ac', 'season_fa'], axis=1, inplace=True)\n",
    "\n",
    "# Since we now have day of the week, I'll drop the day coloumns\n",
    "#df_temp.drop(['day_ac', 'day_fa'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labelling values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, I will combine train and test sets into a temporary dataframe to fill missing values using knn.\n",
    "# The temp dataframe will be seperated back into train and test sets after imputation.\n",
    "# first_affiliate_tracked coloumn has null values that need to be imputed.\n",
    "# country_destination will have new null values after combining datasets.\n",
    "# Non-null values of first_affiliate_tracked and country_destination will be encoded seperately and inserted back into df_temp using numpy squeeze.\n",
    "\n",
    "#df_temp = pd.concat([df_train,df_test], keys=[0,1])\n",
    "\n",
    "categories = ['gender', 'signup_method', 'signup_flow', 'language',  'affiliate_channel', 'affiliate_provider', 'signup_app', 'first_device_type', 'first_browser']\n",
    "le = LabelEncoder()\n",
    "le_f = LabelEncoder()\n",
    "\n",
    "first_affiliate_nonulls = np.array(df_temp['first_affiliate_tracked'].dropna())\n",
    "first_affiliate_nonulls = first_affiliate_nonulls.reshape(-1,1)\n",
    "first_affiliate_encoded = le_f.fit_transform(first_affiliate_nonulls)\n",
    "df_temp['first_affiliate_tracked'].loc[df_temp['first_affiliate_tracked'].notnull()] = np.squeeze(first_affiliate_encoded)\n",
    "\n",
    "country_dest_nonulls = np.array(df_temp['country_destination'].dropna())\n",
    "country_dest_nonulls = country_dest_nonulls.reshape(-1,1)\n",
    "country_dest_encoded = le.fit_transform(country_dest_nonulls)\n",
    "df_temp['country_destination'].loc[df_temp['country_destination'].notnull()] = np.squeeze(country_dest_encoded)\n",
    "\n",
    "for i in categories:\n",
    "    df_temp[i] = le_f.fit_transform(df_temp[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing Values Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# Imputation (This will take ~20 minutes)\n",
    "# You can skip this step. I've already run it and exported the filled df to df_impute.csv (included in main directory)\n",
    "\n",
    "def get_k(n, chunks=10):\n",
    "    k = round(sqrt(n/chunks))\n",
    "    if k % 2 == 0:\n",
    "        return k-1\n",
    "    else:\n",
    "        return k\n",
    "        \n",
    "chunks = 10\n",
    "k = get_k(n=df_temp.shape[0], chunks=chunks)\n",
    "df_temp_2 = df_temp.copy()\n",
    "df_temp_2.drop(['country_destination'], axis=1, inplace=True)\n",
    "cols = list(df_temp_2.columns)\n",
    "df_impute = pd.DataFrame()\n",
    "\n",
    "for chunk in np.array_split(df_temp_2, chunks):\n",
    "    chunk = np.round(KNN(k=k).fit_transform(chunk))\n",
    "    df_chunk = pd.DataFrame(data=chunk, columns=cols)\n",
    "    df_impute = pd.concat([df_impute, df_chunk], axis=0, ignore_index=True)\n",
    "\n",
    "df_impute.to_csv('df_impute.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run this cell if you skipped the previous one.\n",
    "df_impute = pd.read_csv('df_impute.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "No null values in df_impute.\n\nOriginal shape\tFilled shape\n(275547, 20)\t(275547, 20)\n\nOriginal\t\tFilled\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": "<table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>age</th>\n      <th>first_affiliate_tracked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"10\" valign=\"top\">0</th>\n      <th>0</th>\n      <td>NaN</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>38.0</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>56.0</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>42.0</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>41.0</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>NaN</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>46.0</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>47.0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>50.0</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>46.0</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table style=\"display:inline\"><table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>age</th>\n      <th>first_affiliate_tracked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"10\" valign=\"top\">0</th>\n      <th>0</th>\n      <td>38.0</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>38.0</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>56.0</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>42.0</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>41.0</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>39.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>46.0</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>47.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>50.0</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>46.0</td>\n      <td>3.0</td>\n    </tr>\n  </tbody>\n</table style=\"display:inline\">"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\nOriginal train\t\tFilled train\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": "<table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>first_affiliate_tracked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>NaN</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>38.0</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>56.0</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>42.0</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>41.0</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>NaN</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>46.0</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>47.0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>50.0</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>46.0</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table style=\"display:inline\"><table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>first_affiliate_tracked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>38.0</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>38.0</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>56.0</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>42.0</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>41.0</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>39.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>46.0</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>47.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>50.0</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>46.0</td>\n      <td>3.0</td>\n    </tr>\n  </tbody>\n</table style=\"display:inline\">"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\nOriginal test\t\tFilled test\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": "<table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>first_affiliate_tracked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>35.0</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>NaN</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>NaN</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>28.0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>48.0</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>NaN</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>NaN</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>NaN</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table style=\"display:inline\"><table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>first_affiliate_tracked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>35.0</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>35.0</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>41.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>41.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>34.0</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>28.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>48.0</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>34.0</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>34.0</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>38.0</td>\n      <td>3.0</td>\n    </tr>\n  </tbody>\n</table style=\"display:inline\">"
     },
     "metadata": {}
    }
   ],
   "source": [
    "# This cell is just for making sure nothing is messed up before imputing into df_temp\n",
    "# Check for null values\n",
    "\n",
    "x = 0\n",
    "for i in df_impute.columns:\n",
    "    sum = df_impute[i].isnull().sum()\n",
    "    if sum != 0:\n",
    "        print(i + ' has: {}'.format(sum) + ' NaN')\n",
    "        x += 1\n",
    "if x == 0:\n",
    "    print('No null values in df_impute.\\n')\n",
    "\n",
    "# First, insert imputed values from df_impute into a new temp df to ensure order\n",
    "age_imputed = df_impute['age'].to_numpy()\n",
    "fa_imputed = df_impute['first_affiliate_tracked'].to_numpy()\n",
    "\n",
    "df_temp_4 = df_temp.copy()\n",
    "df_temp_4['age'] = age_imputed\n",
    "df_temp_4['first_affiliate_tracked'] = fa_imputed\n",
    "\n",
    "print('Original shape\\tFilled shape')\n",
    "print(''+str(df_temp.shape)+'\\t'+str(df_temp_4.shape))\n",
    "\n",
    "print('\\nOriginal\\t\\tFilled')\n",
    "display_side_by_side(df_temp[['age', 'first_affiliate_tracked']].head(10), df_temp_4[['age', 'first_affiliate_tracked']].head(10))\n",
    "\n",
    "#splitting df_temp\n",
    "df_train_2, df_test_2 = df_temp.xs(0), df_temp.xs(1)\n",
    "df_test_2.drop(['country_destination'], axis=1, inplace=True)\n",
    "\n",
    "#splitting df_temp_4\n",
    "df_train_3, df_test_3 = df_temp_4.xs(0), df_temp_4.xs(1)\n",
    "df_test_3.drop(['country_destination'], axis=1, inplace=True)\n",
    "\n",
    "print('\\nOriginal train\\t\\tFilled train')\n",
    "display_side_by_side(df_train_2[['age', 'first_affiliate_tracked']].head(10), df_train_3[['age', 'first_affiliate_tracked']].head(10))\n",
    "print('\\nOriginal test\\t\\tFilled test')\n",
    "display_side_by_side(df_test_2[['age', 'first_affiliate_tracked']].head(10), df_test_3[['age', 'first_affiliate_tracked']].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Now that we can split the data back safely, we can apply this on our data\n",
    "\n",
    "age_imputed = df_impute['age'].to_numpy()\n",
    "fa_imputed = df_impute['first_affiliate_tracked'].to_numpy()\n",
    "\n",
    "df_temp['age'] = age_imputed\n",
    "df_temp['first_affiliate_tracked'] = fa_imputed\n",
    "\n",
    "df_target = df_temp.xs(0)['country_destination']\n",
    "target = df_target.values\n",
    "\n",
    "df_temp.drop(['country_destination'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Encoding Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "categories = ['gender', 'signup_method', 'signup_flow', 'language',  'affiliate_channel', 'affiliate_provider', 'first_affiliate_tracked', 'signup_app', 'first_device_type', 'first_browser']\n",
    "ct = ColumnTransformer([('encoder', OneHotEncoder(), categories)], remainder='passthrough')\n",
    "matrix = ct.fit_transform(df_temp)\n",
    "df = pd.DataFrame(matrix)\n",
    "train = df[:len(df_train)]\n",
    "test = df[len(df_train):]\n",
    "\n",
    "train = train.values\n",
    "test = test.values\n",
    "df_target = df_target.astype(int)\n",
    "target = df_target.values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train, target, test_size=0.33, random_state=28, shuffle=True)\n",
    "\n",
    "pd.DataFrame(X_train).to_csv('X_train.csv')\n",
    "pd.DataFrame(X_test).to_csv('X_test.csv')\n",
    "pd.DataFrame(y_train).to_csv('y_train.csv')\n",
    "pd.DataFrame(y_test).to_csv('y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This is a multi-class classification problem. The prediction output for each row is the top 5 country destinations\n",
    "# with highest probability. Using sklearn accuracy metric won't give real accuracy.\n",
    "# NDCG (Normalized Discounted Cumulative Gain) is the evaluation metric used for this competition.\n",
    "\n",
    "def acc_ndcg(y_test, y_pred_proba):\n",
    "    acc = []\n",
    "    for i in range(len(y_pred_proba)):\n",
    "        p = np.argsort(y_pred_proba[i])[-5:][::-1]\n",
    "        t = y_test[i]\n",
    "        try:\n",
    "            index = int(np.where(p == t)[0][0]+1)\n",
    "            dcg = 1/(log2(index + 1))\n",
    "        except:\n",
    "            dcg = 0.0\n",
    "        acc.append(dcg)\n",
    "    return np.mean(acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# CatBoostClassifier max_depth grid search (This will take a very long time. Results are included in pdf)\n",
    "# The code for the grid search is taken from this webpage: https://machinelearningmastery.com/tune-number-size-decision-trees-xgboost-python/\n",
    "\n",
    "model = catboost.CatBoostClassifier(loss_function='MultiClass', task_type='GPU')\n",
    "max_depth = range(7, 16, 1)\n",
    "param_grid = dict(max_depth=max_depth)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "grid_search = GridSearchCV(model, param_grid, scoring=\"neg_log_loss\")\n",
    "grid_result = grid_search.fit(train, target)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "\tprint(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "plt.errorbar(max_depth, means, yerr=stds)\n",
    "plt.title(\"CatBoost max_depth vs Log Loss\")\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('Log Loss')\n",
    "plt.savefig('catboost_max_depth_2.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# CatBoostClassifier learning_rate grid search (This will take a very long time. Results are included in pdf)\n",
    "# The code for the grid search is taken from this webpage: https://machinelearningmastery.com/tune-number-size-decision-trees-xgboost-python/\n",
    "\n",
    "model = catboost.CatBoostClassifier(loss_function='MultiClass', task_type='GPU', max_depth=11)\n",
    "learning_rate = np.arange(0.01, 0.08, 0.01)\n",
    "param_grid = dict(learning_rate=learning_rate)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "grid_search = GridSearchCV(model, param_grid, scoring=\"neg_log_loss\")\n",
    "grid_result = grid_search.fit(train, target)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "\tprint(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "plt.errorbar(learning_rate, means, yerr=stds)\n",
    "plt.title(\"CatBoost learning_rate vs Log Loss\")\n",
    "plt.xlabel('learning_rate')\n",
    "plt.ylabel('Log Loss')\n",
    "plt.savefig('catboost_learning_rate2.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# CatBoostClassifier Training\n",
    "\n",
    "clf_cb = CatBoostClassifier(loss_function='MultiClass', task_type='GPU', max_depth=11, iterations=1000, learning_rate=0.01, random_state=28, logging_level='Verbose')\n",
    "clf_cb.fit(X_train, y_train)\n",
    "\n",
    "y_pred_proba = clf_cb.predict_proba(X_test)\n",
    "y_pred = clf_cb.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy of CatBoost: %s'%(acc))\n",
    "lloss = log_loss(y_test, y_pred_proba)\n",
    "print('Log Loss of Catboost: %s'%(lloss))\n",
    "ndcg = acc_ndcg(y_test, y_pred_proba)\n",
    "print('NDCG of CatBoost: %s'%(ndcg))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix of CatBoost:\\n%s'%(cm))\n",
    "\n",
    "clf_cb.save_model(str(type(clf_cb).__name__)+'.json', format='json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# XGBClassifier n_estimators grid search (This will take a long time. Results are included in pdf)\n",
    "# The code for the grid search is taken from this webpage: https://machinelearningmastery.com/tune-number-size-decision-trees-xgboost-python/\n",
    "\n",
    "model = XGBClassifier()\n",
    "n_estimators = range(10, 35, 5)\n",
    "param_grid = dict(n_estimators=n_estimators)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=28)\n",
    "grid_search = GridSearchCV(model, param_grid, scoring=\"neg_log_loss\", n_jobs=-1, cv=kfold)\n",
    "grid_result = grid_search.fit(X_train, y_train)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "\tprint(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "plt.errorbar(n_estimators, means, yerr=stds)\n",
    "plt.title(\"XGBoost n_estimators vs Log Loss\")\n",
    "plt.xlabel('n_estimators')\n",
    "plt.ylabel('Log Loss')\n",
    "plt.savefig('n_estimators.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# XGBClassifier learning_rate grid search (This will take a long time. Results are included in pdf)\n",
    "# The code for the grid search is taken from this webpage: https://machinelearningmastery.com/tune-number-size-decision-trees-xgboost-python/\n",
    "\n",
    "model = XGBClassifier(n_estimators=25)\n",
    "learning_rate = np.arange(0.2, 0.5, 0.05)\n",
    "param_grid = dict(learning_rate=learning_rate)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=28)\n",
    "grid_search = GridSearchCV(model, param_grid, scoring=\"neg_log_loss\", n_jobs=-1, cv=kfold)\n",
    "grid_result = grid_search.fit(X_train, y_train)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "\tprint(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "plt.errorbar(learning_rate, means, yerr=stds)\n",
    "plt.title(\"XGBoost learning_rate vs Log Loss\")\n",
    "plt.xlabel('learning_rate')\n",
    "plt.ylabel('Log Loss')\n",
    "plt.savefig('learning_rate.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# XGBClassifier max_depth grid search (This will take a long time. Results are included in pdf)\n",
    "# The code for the grid search is taken from this webpage: https://machinelearningmastery.com/tune-number-size-decision-trees-xgboost-python/\n",
    "\n",
    "model = XGBClassifier(n_estimators=25, learning_rate=0.3)\n",
    "max_depth = range(3, 10, 1)\n",
    "param_grid = dict(max_depth=max_depth)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=28)\n",
    "grid_search = GridSearchCV(model, param_grid, scoring=\"neg_log_loss\", n_jobs=-1, cv=kfold)\n",
    "grid_result = grid_search.fit(X_train, y_train)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "\tprint(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "plt.errorbar(max_depth, means, yerr=stds)\n",
    "plt.title(\"XGBoost max_depth vs Log Loss\")\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('Log Loss')\n",
    "plt.savefig('max_depth.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# XGBClassifier Training\n",
    "\n",
    "clf_xgb = XGBClassifier(max_depth=5, learning_rate=0.3, n_estimators=25, objective='multi:softprob', colsample_bytree=0.6, seed=28, verbosity=1)\n",
    "clf_xgb.fit(X_train, y_train)\n",
    "y_pred= clf_xgb.predict(X_test)\n",
    "y_pred_proba = clf_xgb.predict_proba(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy of XGB: %s'%(acc))\n",
    "lloss = log_loss(y_test, y_pred_proba)\n",
    "print('Log Loss of XGB: %s'%(lloss))\n",
    "ndcg = acc_ndcg(y_test, y_pred_proba)\n",
    "print('NDCG of XGB: %s'%(ndcg))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix of XGB:\\n%s'%(cm))\n",
    "\n",
    "clf_xgb.save_model(str(type(clf_xgb).__name__)+'.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DecisionTreeClassifier max_depth grid search (Results are included in pdf)\n",
    "# The code for the grid search is taken from this webpage: https://machinelearningmastery.com/tune-number-size-decision-trees-xgboost-python/\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "max_depth = range(2, 10, 1)\n",
    "param_grid = dict(max_depth=max_depth)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=28)\n",
    "grid_search = GridSearchCV(model, param_grid, scoring=\"neg_log_loss\", n_jobs=-1, cv=kfold)\n",
    "grid_result = grid_search.fit(X_train, y_train)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "\tprint(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "plt.errorbar(max_depth, means, yerr=stds)\n",
    "plt.title(\"DTree max_depth vs Log Loss\")\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('Log Loss')\n",
    "plt.savefig('dtree_max_depth.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DecisionTreeClassifier Training\n",
    "\n",
    "clf_dtree = DecisionTreeClassifier(max_depth=4)\n",
    "clf_dtree.fit(X_train, y_train)\n",
    "y_pred= clf.predict(X_test)\n",
    "y_pred_proba = clf_dtree.predict_proba(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy of DTree: %s'%(acc))\n",
    "ndcg = acc_ndcg(y_test, y_pred_proba)\n",
    "print('NDCG of DTree: %s'%(ndcg))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix of DTree:\\n%s'%(cm))\n",
    "\n",
    "joblib.dump(clf_dtree, str(type(clf_dtree).__name__)+'.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SVM Training\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, target, test_size=0.33, random_state=28, shuffle=True)\n",
    "\n",
    "clf_svm = SVC(decision_function_shape='ovo', probability=True, random_state=28)\n",
    "clf_svm.fit(X_train, y_train)\n",
    "y_pred= clf_svm.predict(X_test)\n",
    "y_pred_proba = clf_svm.predict_proba(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy of SVM: %s'%(acc))\n",
    "ndcg = acc_ndcg(y_test, y_pred_proba)\n",
    "print('NDCG of SVM: %s'%(ndcg))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix of SVM:\\n%s'%(cm))\n",
    "\n",
    "joblib.dump(clf_svm, 'SVM.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# RandomForestClassifier max_depth grid search (Results are included in pdf)\n",
    "# The code for the grid search is taken from this webpage: https://machinelearningmastery.com/tune-number-size-decision-trees-xgboost-python/\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "max_depth = range(2, 16, 1)\n",
    "param_grid = dict(max_depth=max_depth)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=28)\n",
    "grid_search = GridSearchCV(model, param_grid, scoring=\"neg_log_loss\", n_jobs=-1, cv=kfold)\n",
    "grid_result = grid_search.fit(X_train, y_train)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "\tprint(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "plt.errorbar(max_depth, means, yerr=stds)\n",
    "plt.title(\"RandomForrest max_depth vs Log Loss\")\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('Log Loss')\n",
    "plt.savefig('RandomForrest_max_depth.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# RandomForestClassifier n_estimators grid search (Results are included in pdf)\n",
    "# The code for the grid search is taken from this webpage: https://machinelearningmastery.com/tune-number-size-decision-trees-xgboost-python/\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "n_estimators = range(50, 300, 50)\n",
    "param_grid = dict(n_estimators=n_estimators)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=28)\n",
    "grid_search = GridSearchCV(model, param_grid, scoring=\"neg_log_loss\", n_jobs=-1, cv=kfold)\n",
    "grid_result = grid_search.fit(X_train, y_train)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "\tprint(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "plt.errorbar(n_estimators, means, yerr=stds)\n",
    "plt.title(\"RandomForrest n_estimators vs Log Loss\")\n",
    "plt.xlabel('n_estimators')\n",
    "plt.ylabel('Log Loss')\n",
    "plt.savefig('RandomForrest_n_estimators.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# RandomForestClassifier min_samples_split grid search (Results are included in pdf)\n",
    "# The code for the grid search is taken from this webpage: https://machinelearningmastery.com/tune-number-size-decision-trees-xgboost-python/\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=250, criterion='entropy', max_depth=11)\n",
    "min_samples_split = range(50, 350, 25)\n",
    "param_grid = dict(min_samples_split=min_samples_split)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=28)\n",
    "grid_search = GridSearchCV(model, param_grid, scoring=\"neg_log_loss\", n_jobs=-1, cv=kfold)\n",
    "grid_result = grid_search.fit(X_train, y_train)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "\tprint(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "plt.errorbar(min_samples_split, means, yerr=stds)\n",
    "plt.title(\"RandomForrest min_samples_split vs Log Loss\")\n",
    "plt.xlabel('min_samples_split')\n",
    "plt.ylabel('Log Loss')\n",
    "plt.savefig('RandomForrest_min_samples_split.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# RandomForestClassifier min_samples_leaf grid search (Results are included in pdf)\n",
    "# The code for the grid search is taken from this webpage: https://machinelearningmastery.com/tune-number-size-decision-trees-xgboost-python/\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=250, criterion='entropy', max_depth=11, min_samples_split=50)\n",
    "min_samples_leaf = range(50, 350, 25)\n",
    "param_grid = dict(min_samples_leaf=min_samples_leaf)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=28)\n",
    "grid_search = GridSearchCV(model, param_grid, scoring=\"neg_log_loss\", n_jobs=-1, cv=kfold)\n",
    "grid_result = grid_search.fit(X_train, y_train)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "\tprint(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "plt.errorbar(min_samples_leaf, means, yerr=stds)\n",
    "plt.title(\"RandomForrest min_samples_leaf vs Log Loss\")\n",
    "plt.xlabel('min_samples_leaf')\n",
    "plt.ylabel('Log Loss')\n",
    "plt.savefig('RandomForrest_min_samples_leaf.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# RandomForestClassifier Training \n",
    "\n",
    "clf_rndforrest = RandomForestClassifier(n_estimators=250, criterion='entropy', max_depth=11, min_samples_split=50, min_samples_leaf=50)\n",
    "\n",
    "clf_rndforrest.fit(X_train, y_train)\n",
    "y_pred = clf_rndforrest.predict(X_test)\n",
    "y_pred_proba = clf_rndforrest.predict_proba(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy of RandomForrest: %s'%(acc))\n",
    "ndcg = acc_ndcg(y_test, y_pred_proba)\n",
    "print('ndcg of RandomForrest: %s'%(ndcg))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix of RandomForrest:\\n%s'%(cm))\n",
    "\n",
    "joblib.dump(clf_rndforrest, str(type(clf_rndforrest).__name__)+'.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# KNeighborsClassifier k grid search (Results are included in pdf)\n",
    "# The code for the grid search is taken from this webpage: https://machinelearningmastery.com/tune-number-size-decision-trees-xgboost-python/\n",
    "\n",
    "def get_k(n):\n",
    "    k = round(sqrt(n))\n",
    "    if k % 2 == 0:\n",
    "        return k-1\n",
    "    else:\n",
    "        return k\n",
    "\n",
    "model = KNeighborsClassifier(weights='distance')\n",
    "n_neighbors = range(5, get_k(len(train))+20, 10)\n",
    "param_grid = dict(n_neighbors=n_neighbors)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=28)\n",
    "grid_search = GridSearchCV(model, param_grid, scoring=\"neg_log_loss\", n_jobs=-1, cv=kfold)\n",
    "grid_result = grid_search.fit(X_train, y_train)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "\tprint(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "plt.errorbar(n_neighbors, means, yerr=stds)\n",
    "plt.title(\"KNN n_neighbors vs Log Loss\")\n",
    "plt.xlabel('n_neighbors')\n",
    "plt.ylabel('Log Loss')\n",
    "plt.savefig('KNN_n_neighbors.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# KNeighborsClassifier Training\n",
    "\n",
    "clf_knn = KNeighborsClassifier(n_neighbors=475, weights='distance')\n",
    "\n",
    "clf_knn.fit(X_train, y_train)\n",
    "y_pred = clf_knn.predict(X_test)\n",
    "y_pred_proba = clf_knn.predict_proba(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy of KNN: %s'%(acc))\n",
    "ndcg = acc_ndcg(y_test, y_pred_proba)\n",
    "print('ndcg of KNN: %s'%(ndcg))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix of KNN:\\n%s'%(cm))\n",
    "\n",
    "joblib.dump(clf_knn, str(type(clf_knn).__name__)+'.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Predicting\n",
    "\n",
    "y_pred_proba = clf_cb.predict_proba(test)\n",
    "predictions = pd.DataFrame(columns=['id', 'country_destination'])\n",
    "temp = pd.read_csv('test_users.csv')\n",
    "temp = temp['id'].values\n",
    "idx = []\n",
    "cd = []\n",
    "for i in temp:\n",
    "    for _ in range(5):\n",
    "        idx.append(i)\n",
    "idx = np.array(idx)\n",
    "predictions['id'] = idx\n",
    "\n",
    "for i in range(len(y_pred_proba)):\n",
    "    pred = le.inverse_transform(np.argsort(y_pred_proba[i])[-5:][::-1])\n",
    "    for p in pred:\n",
    "        cd.append(p)\n",
    "cd = np.array(cd)\n",
    "predictions['country_destination'] = cd\n",
    "predictions.to_csv('predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.head()"
   ]
  }
 ]
}